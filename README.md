ABOUT THE PROJECT

The project is divided into three parts as per the assignment.
1. Web scrapping the Wikipedia page using requests and Beautiful Soup.
2. Extracting data from CSV files and creating the required dataframes.
3. Using Geocoder Python package to find the latitude and the longitudes of a location, using Foursqaure's REST API for finding the location data of nearby venues of
a given location, data wrangling and segmentation using pandas and Numpy, Data Clustering using Machine Learning algorithm - K Means,
Data Visualization using Folium and matplotlib.


The aim is to cluster the neighborhoods in the city of Toronto based on the postal code and borough information given on wikipedia link:
https://en.wikipedia.org/wiki/Postal_code#:~:text=A

Here we scraped the Wikipedia page and wrangled the data, cleaned it and then read it itno a pandas dataframe so that it is in a structured format.
Once the data is in the required format, exploring and clustering the neighborhoods in the city of Toronto was done.

The top 5 most coomon venues were found for each neighborhood.

